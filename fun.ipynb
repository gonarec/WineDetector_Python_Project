{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_outliers_with_median(df):\n",
    "    df_clean = df.copy()  # Copia il DataFrame originale per non modificarlo direttamente\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col != 'quality':\n",
    "            q1 = df[col].quantile(0.25)  # Calcola il primo quartile\n",
    "            q3 = df[col].quantile(0.75)  # Calcola il terzo quartile\n",
    "            iqr = q3 - q1  # Calcola l'interquartile range (IQR)\n",
    "\n",
    "            # Calcola i limiti per gli outlier\n",
    "            lower_bound = q1 - 1.5 * iqr\n",
    "            upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "            # Sostituisci gli outlier con la mediana\n",
    "            median = df_clean[col].median()\n",
    "            df_clean[col] = df_clean[col].apply(lambda x: median if x < lower_bound or x > upper_bound else x)\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "def replace_outliers_with_mean(df):\n",
    "    df_clean = df.copy()  # Copia il DataFrame originale per non modificarlo direttamente\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col != 'quality':\n",
    "            q1 = df[col].quantile(0.25)  # Calcola il primo quartile\n",
    "            q3 = df[col].quantile(0.75)  # Calcola il terzo quartile\n",
    "            iqr = q3 - q1  # Calcola l'interquartile range (IQR)\n",
    "\n",
    "            # Calcola i limiti per gli outlier\n",
    "            lower_bound = q1 - 1.5 * iqr\n",
    "            upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "            # Sostituisci gli outlier con la mediana\n",
    "            mean = df_clean[col].mean()\n",
    "            df_clean[col] = df_clean[col].apply(lambda x: mean if x < lower_bound or x > upper_bound else x)\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "def remove_outliers(df):\n",
    "\n",
    "    df_clean = df.copy()  # Copia il DataFrame originale per non modificarlo direttamente\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col != 'quality':\n",
    "            q1 = df[col].quantile(0.25)  # Calcola il primo quartile\n",
    "            q3 = df[col].quantile(0.75)  # Calcola il terzo quartile\n",
    "            iqr = q3 - q1  # Calcola l'interquartile range (IQR)\n",
    "\n",
    "            # Calcola i limiti per gli outlier\n",
    "            lower_bound = q1 - 1.5 * iqr\n",
    "            upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "            # Rimuovi gli outlier\n",
    "            df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "def new_quality_value(df):\n",
    "    \n",
    "    new_df = df.copy()\n",
    "    # Mappa i valori della colonna 'quality' \n",
    "    quality_mapping = {3: 0, 4: 0, 5: 1, 6: 1, 7: 2, 8: 2}\n",
    "    new_df['quality'] = new_df['quality'].replace(quality_mapping)\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "def classificator (dataset, classifier):\n",
    "    accuracy_dict={}\n",
    "    x_data=dataset.drop(columns=[classifier])\n",
    "    y_data=dataset.loc[:,classifier]\n",
    "    x_train,x_test,y_train,y_test=train_test_split(x_data,y_data,test_size=0.10,random_state=10)\n",
    "\n",
    "    # RandomForestClassifier \n",
    "    rf_model = RandomForestClassifier(n_estimators=1000, random_state=20)\n",
    "    rf_model.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = rf_model.predict(x_test)\n",
    "\n",
    "    # Valutazione delle prestazioni del modello\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    #print(\"Accuratezza del modello RandomForestClassifier: %.3f\" %accuracy)\n",
    "    accuracy_dict['RandomForest']=round(accuracy,3)\n",
    "\n",
    "    # Classificatore SVM con solo relevant feature\n",
    "    svm_classifier = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
    "\n",
    "    svm_classifier.fit(x_train, y_train)\n",
    "    y_pred = svm_classifier.predict(x_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    #print(\"Accuratezza del classificatore SVM: %.3f\" %accuracy)\n",
    "    accuracy_dict['SVM']=round(accuracy,3)\n",
    "\n",
    "    # Crea il modello di regressione logistica con solo relevant\n",
    "    logistic_regression = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=10000, random_state=42)\n",
    "\n",
    "    logistic_regression.fit(x_train, y_train)\n",
    "    y_pred = logistic_regression.predict(x_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    #print(\"Accuratezza del modello di regressione logistica: %.3f\" %accuracy)\n",
    "    accuracy_dict['Regression']=accuracy\n",
    "\n",
    "    # DecisionTreeClassifier con tutte le feature\n",
    "    tree_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "    tree_classifier.fit(x_train, y_train)\n",
    "    y_pred = tree_classifier.predict(x_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    #print(\"Accuratezza del classificatore ad albero decisionale: %.3f\" %accuracy)\n",
    "    accuracy_dict['Tree']=round(accuracy,3)\n",
    "\n",
    "\n",
    "    # Classificatore naive bayes con relevant feature\n",
    "    naive_bayes_classifier = GaussianNB()\n",
    "    naive_bayes_classifier.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = naive_bayes_classifier.predict(x_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    #print(\"Accuratezza del classificatore Naive Bayes: %.3f\" %accuracy)\n",
    "    accuracy_dict['Bayes']=round(accuracy,3)\n",
    "\n",
    "    return accuracy_dict\n",
    "\n",
    "def plot_boxplots(dataframe):\n",
    "    num_plots = len(dataframe.columns) - 1  \n",
    "    cols_per_row = 4 \n",
    "\n",
    "    # Calcola il numero di righe necessarie\n",
    "    num_rows = (num_plots - 1) // cols_per_row + 1\n",
    "\n",
    "    # Crea il layout dei subplot\n",
    "    fig, axes = plt.subplots(num_rows, cols_per_row, figsize=(15, 5 * num_rows))\n",
    "\n",
    "    # Flatten l'array di assi se è multidimensionale\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Itera sulle colonne del DataFrame escludendo \"quality\"\n",
    "    for i, col in enumerate(dataframe.drop(columns='quality')):\n",
    "        # Seleziona l'asse corrente\n",
    "        ax = axes[i]\n",
    "\n",
    "        # Disegna il boxplot per la feature corrente con \"quality\" sulle x\n",
    "        sns.boxplot(x='quality', y=col, data=dataframe, ax=ax, palette='coolwarm', hue='quality', legend=False)\n",
    "\n",
    "        # Imposta il titolo del boxplot\n",
    "        ax.set_title(f'Boxplot di {col}')\n",
    "\n",
    "        # Ruota le etichette sull'asse x per una migliore leggibilità\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "        # Imposta le etichette sull'asse y con precisione a tre cifre decimali\n",
    "        ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{x:.3f}'))\n",
    "\n",
    "    # Rimuovi gli assi vuoti se ce ne sono\n",
    "    for ax in axes[num_plots:]:\n",
    "        ax.remove()\n",
    "\n",
    "    # Imposta il layout dei subplot\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Mostra il grafico\n",
    "    plt.show()\n",
    "\n",
    "def plot_boxplots_comparision(dataframe_1, dataframe_clean_1):\n",
    "    dataframe=dataframe_1.copy()\n",
    "    dataframe_clean=dataframe_clean_1.copy()\n",
    "    num_plots = len(dataframe.columns) - 1 # Numero di colonne nel DataFrame escludendo \"quality\" e Dataset\n",
    "    cols_per_row = 4 \n",
    "\n",
    "    # Calcola il numero di righe necessarie\n",
    "    num_rows = (num_plots - 1) // cols_per_row + 1\n",
    "\n",
    "    # Crea il layout dei subplot\n",
    "    fig, axes = plt.subplots(num_rows, cols_per_row, figsize=(15, 5 * num_rows))\n",
    "\n",
    "    # Flatten l'array di assi se è multidimensionale\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Concateniamo i DataFrame relevant e relevant_clean, aggiungendo una colonna 'Dataset' per distinguere tra i due\n",
    "    dataframe['Dataset'] = 'Prima'\n",
    "    dataframe_clean['Dataset'] = 'Dopo'\n",
    "\n",
    "    # Uniamo i DataFrame\n",
    "    combined_df = pd.concat([dataframe, dataframe_clean])\n",
    "\n",
    "    # Iteriamo su ogni feature\n",
    "    for i, col in enumerate(dataframe.columns):\n",
    "        if col != 'quality' and col != 'Dataset':\n",
    "            ax = axes[i]\n",
    "            sns.boxplot(x='Dataset', y=col, data=combined_df, hue='Dataset', palette=[\"blue\", \"orange\"], ax=ax)\n",
    "            ax.set_title(f'Rimozione Outlier di {col}')\n",
    "            \n",
    "    # Rimuovi gli assi vuoti se ce ne sono\n",
    "    for ax in axes[num_plots:]:\n",
    "        ax.remove()\n",
    "\n",
    "    # Imposta il layout dei subplot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_bar_chart_df(df):\n",
    "    if type(df) == pd.DataFrame:\n",
    "        keys = df.index.tolist()  # Ottieni gli indici del DataFrame come chiavi\n",
    "        values = df.iloc[:, 0].tolist()  # Ottieni i valori dalla prima colonna del DataFrame\n",
    "    elif type(df) == pd.Series:\n",
    "        keys = df.index.tolist()\n",
    "        values = df.tolist()\n",
    "\n",
    "    colors = plt.cm.RdBu(np.array(values) / max(values))  # Utilizza la mappa di colori \"RdBu\" in base ai valori massimi\n",
    "\n",
    "    # Aggiungi valori sulle barplot\n",
    "    for i, v in enumerate(values):\n",
    "        plt.text(i, v + 0.01, f\"{v:.2f}\", ha='center', va='bottom')\n",
    "    \n",
    "    plt.bar(keys, values, color=colors)\n",
    "    plt.xlabel('Algoritmi')\n",
    "    plt.ylabel('Performance')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.ylim(0, max(values) * 1.2)  # Estendi l'asse y del 10%\n",
    "    plt.show()\n",
    "\n",
    "def plot_result(res):\n",
    "    num_cols = len(result.columns)\n",
    "    num_rows = (num_cols + 1) // 2 \n",
    "\n",
    "    # Creazione del grafico a barre\n",
    "    fig, axs = plt.subplots(num_rows, 2, figsize=(15, 5*num_rows))\n",
    "\n",
    "    # Itera sul DataFrame e crea i subplot\n",
    "    for i, (col_name, col_data) in enumerate(result.items()):\n",
    "        row = i // 2\n",
    "        col = i % 2\n",
    "        keys = result.index\n",
    "        values = col_data\n",
    "        colors = plt.cm.RdBu(np.array(values) / max(values))\n",
    "        \n",
    "        for j, v in enumerate(values):\n",
    "            axs[row, col].text(j, v + 0.01, f\"{v:.2f}\", ha='center', va='bottom')\n",
    "        \n",
    "        axs[row, col].bar(keys, values, color=colors)\n",
    "        axs[row, col].set_ylabel('Valori')\n",
    "        axs[row, col].set_title('Dataset name='+col_name)\n",
    "        axs[row, col].set_xticks(keys)\n",
    "        axs[row, col].set_xticklabels(keys, rotation=45, ha='right')\n",
    "        axs[row, col].set_ylim(0, max(values) * 1.2)\n",
    "\n",
    "    # Rimuovi i subplot non utilizzati\n",
    "    for i in range(num_cols, num_rows*2):\n",
    "        fig.delaxes(axs.flatten()[i])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def classificator_evo (dataset, classifier, testsize):\n",
    "    accuracy_dict={}\n",
    "    x_data=dataset.drop(columns=[classifier])\n",
    "    y_data=dataset.loc[:,classifier]\n",
    "    x_train,x_test,y_train,y_test=train_test_split(x_data,y_data,test_size=testsize,random_state=10)\n",
    "\n",
    "    accuracy_dict['Size']= dataset.shape[0]\n",
    "    \n",
    "    # RandomForestClassifier \n",
    "    rf_model = RandomForestClassifier(n_estimators=1000, random_state=20)\n",
    "    rf_model.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = rf_model.predict(x_test)\n",
    "\n",
    "    # Valutazione delle prestazioni del modello\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    #print(\"Accuratezza del modello RandomForestClassifier: %.3f\" %accuracy)\n",
    "    accuracy_dict['RandomForest']=round(accuracy,3)\n",
    "\n",
    "    # Classificatore SVM con solo relevant feature\n",
    "    svm_classifier = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
    "\n",
    "    svm_classifier.fit(x_train, y_train)\n",
    "    y_pred = svm_classifier.predict(x_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    #print(\"Accuratezza del classificatore SVM: %.3f\" %accuracy)\n",
    "    accuracy_dict['SVM']=round(accuracy,3)\n",
    "\n",
    "    # Crea il modello di regressione logistica con solo relevant\n",
    "    logistic_regression = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=10000, random_state=42)\n",
    "\n",
    "    logistic_regression.fit(x_train, y_train)\n",
    "    y_pred = logistic_regression.predict(x_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    #print(\"Accuratezza del modello di regressione logistica: %.3f\" %accuracy)\n",
    "    accuracy_dict['Regression']=accuracy\n",
    "\n",
    "    # DecisionTreeClassifier con tutte le feature\n",
    "    tree_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "    tree_classifier.fit(x_train, y_train)\n",
    "    y_pred = tree_classifier.predict(x_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    #print(\"Accuratezza del classificatore ad albero decisionale: %.3f\" %accuracy)\n",
    "    accuracy_dict['Tree']=round(accuracy,3)\n",
    "\n",
    "\n",
    "    # Classificatore naive bayes con relevant feature\n",
    "    naive_bayes_classifier = GaussianNB()\n",
    "    naive_bayes_classifier.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = naive_bayes_classifier.predict(x_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    #print(\"Accuratezza del classificatore Naive Bayes: %.3f\" %accuracy)\n",
    "    accuracy_dict['Bayes']=round(accuracy,3)\n",
    "\n",
    "    return accuracy_dict\n",
    "\n",
    "def classification_evo(dataframe, testsize):\n",
    "\n",
    "    data=dataframe.copy()\n",
    "    data_clean_median=replace_outliers_with_median(data)\n",
    "    data_clean_mean=replace_outliers_with_mean(data)\n",
    "    data_clean_remove=remove_outliers(data)\n",
    "\n",
    "    relevant=dataframe.drop(columns=['fixed_acidity','residual_sugar', 'chlorides', 'free_sulfur_dioxide', 'total_sulfur_dioxide', 'density', 'pH'])\n",
    "    relevant_clean_median=replace_outliers_with_median(relevant)\n",
    "    relevant_clean_mean=replace_outliers_with_mean(relevant)\n",
    "    relevant_clean_remove=remove_outliers(relevant)\n",
    "\n",
    "\n",
    "\n",
    "    result=pd.DataFrame()\n",
    "\n",
    "    result['Data'+'_'+str(testsize)]=classificator_evo(data,'quality',testsize)\n",
    "\n",
    "    result['Relevant'+'_'+str(testsize)]=classificator_evo(relevant,'quality', testsize)\n",
    "\n",
    "    result['Data_Clean_Median'+'_'+str(testsize)]=classificator_evo(data_clean_median,'quality', testsize)\n",
    "\n",
    "    result['Relevant_Clean_Median'+'_'+str(testsize)]=classificator_evo(relevant_clean_median, 'quality', testsize)\n",
    "\n",
    "    result['Data_Clean_Mean'+'_'+str(testsize)]=classificator_evo(data_clean_mean,'quality', testsize)\n",
    "\n",
    "    result['Relevant_Clean_Mean'+'_'+str(testsize)]=classificator_evo(relevant_clean_mean, 'quality', testsize)\n",
    "\n",
    "    result['Data_Remove'+'_'+str(testsize)]=classificator_evo(data_clean_remove,'quality', testsize)\n",
    "\n",
    "    result['Relevant_Remove'+'_'+str(testsize)]=classificator_evo(relevant_clean_remove, 'quality', testsize)\n",
    "\n",
    "    return result\n",
    "\n",
    "def plot_result_evo(res):\n",
    "    num=res.iloc[0]\n",
    "    result=res.drop(index= ['Size'])\n",
    "    num_cols = len(result.columns)\n",
    "    num_rows = (num_cols + 1) // 2 \n",
    "\n",
    "    # Creazione del grafico a barre\n",
    "    fig, axs = plt.subplots(num_rows, 2, figsize=(15, 5*num_rows))\n",
    "\n",
    "    # Itera sul DataFrame e crea i subplot\n",
    "    for i, (col_name, col_data) in enumerate(result.items()):\n",
    "        row = i // 2\n",
    "        col = i % 2\n",
    "        keys = result.index\n",
    "        values = col_data\n",
    "        colors = plt.cm.RdBu(np.array(values) / max(values))\n",
    "        \n",
    "        for j, v in enumerate(values):\n",
    "            axs[row, col].text(j, v + 0.01, f\"{v:.2f}\", ha='center', va='bottom')\n",
    "        \n",
    "        axs[row, col].bar(keys, values, color=colors)\n",
    "        axs[row, col].set_ylabel('Valori')\n",
    "        axs[row, col].set_title('Dataset name='+col_name+'   Dataset size='+str(num.iloc[i]))\n",
    "        axs[row, col].set_xticks(keys)\n",
    "        axs[row, col].set_xticklabels(keys, rotation=45, ha='right')\n",
    "        axs[row, col].set_ylim(0, max(values) * 1.2)\n",
    "\n",
    "    # Rimuovi i subplot non utilizzati\n",
    "    for i in range(num_cols, num_rows*2):\n",
    "        fig.delaxes(axs.flatten()[i])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_bar_chart_df_evo(df):\n",
    "  \n",
    "    keys = df.index.tolist()  \n",
    "    values = df.iloc[:, 0].tolist()  \n",
    "    x_labels = [f\"{key}: {df.iloc[i, 1]}\" for i, key in enumerate(keys)]  \n",
    "   \n",
    "\n",
    "    colors = plt.cm.RdBu(np.array(values) / max(values)) \n",
    "\n",
    "    # Aggiungi valori sulle barplot\n",
    "    for i, v in enumerate(values):\n",
    "        plt.text(i, v + 0.01, f\"{v:.2f}\", ha='center', va='bottom')\n",
    "    \n",
    "    plt.bar(keys, values, color=colors)\n",
    "    plt.xlabel('Algoritmi')\n",
    "    plt.ylabel('Performance')\n",
    "    plt.xticks(range(len(keys)), x_labels, rotation=45, ha='right')\n",
    "    plt.ylim(0, max(values) * 1.2)\n",
    "    plt.show()\n",
    "\n",
    "def trova_max(df):\n",
    "    # Trova il massimo in ogni riga\n",
    "    max_values = df.max(axis=1)\n",
    "\n",
    "    # Trova l'indice del massimo in ogni riga\n",
    "    max_indices = df.idxmax(axis=1)\n",
    "\n",
    "    max_df = pd.DataFrame({'Max_Value': max_values, 'Index': max_indices})\n",
    "    return max_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
